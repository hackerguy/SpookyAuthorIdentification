{
    "nbformat_minor": 1, 
    "cells": [
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "<img src=\"https://storage.googleapis.com/kaggle-media/competitions/spooky-books/dmitrij-paskevic-44124.jpg\" style=\"width:200px; float: left; padding-right: 10px\"/>\n<h2 style=\"font-face: verdana; font-size: 32px;\">Spooky Author Identification</h2>\n<h3 style=\"font-face: verdana; font-size: 16px;\">Creating Rich Machine Learning Features with the Watson Cognitive APIs</h3>\n<br><br>\nhttps://www.kaggle.com/c/spooky-author-identification"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Download and unzip the data set"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 1, 
            "source": "import os\nif os.path.isfile('train.zip'):\n    os.remove(\"train.zip\")\nif os.path.isfile('train.csv'):\n    os.remove(\"train.csv\")\nimport wget\nurl = 'https://github.com/hackerguy/SpookyAuthorIdentification/blob/master/train.zip?raw=true'\nwget.download(url)\nimport zipfile\nzip = zipfile.ZipFile('train.zip', 'r')\nzip.extractall()\nzip.close()"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Read in the data set as a Spark DataFrame\n### Infer schema and column names"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 2, 
            "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n\ndata = (spark.read\n  .format('csv')\n  .option('header', 'true')\n  .option(\"inferSchema\", \"true\")\n  .load('train.csv'))"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Display the dataset"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id26305</td>\n      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n      <td>EAP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id17569</td>\n      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n      <td>HPL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id11008</td>\n      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n      <td>EAP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27763</td>\n      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n      <td>MWS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id12958</td>\n      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n      <td>HPL</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "        id  \\\n0  id26305   \n1  id17569   \n2  id11008   \n3  id27763   \n4  id12958   \n\n                                                                                                                                                                                                                                      text  \\\n0  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n1  It never once occurred to me that the fumbling might be a mere mistake.                                                                                                                                                                   \n2  In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.                                  \n3  How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.                            \n4  Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.                                                            \n\n  author  \n0  EAP    \n1  HPL    \n2  EAP    \n3  MWS    \n4  HPL    "
                    }, 
                    "execution_count": 3
                }
            ], 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "execution_count": 3, 
            "source": "import pandas as pd\npd.set_option('display.max_colwidth', -1)\ndata.toPandas().head()"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Remove rows that do not have valid author fields"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 4, 
            "source": "data = data.filter((data['author']=='EAP')| (data['author']=='HPL') | (data['author']=='MWS'))"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Show the schema of the data including data types"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- id: string (nullable = true)\n |-- text: string (nullable = true)\n |-- author: string (nullable = true)\n\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 5, 
            "source": "data.printSchema()"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Limit the data size for processing efficiency"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 6, 
            "source": "data = data.limit(100)"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### Dataset Overview - number of rows and columns"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "There are 100 observations in the survey dataset.\nThere are 3 variables in the dataset.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 7, 
            "source": "print(\"There are \" + str(data.count()) + \" observations in the survey dataset.\")\nprint(\"There are \" + str(len(data.columns)) + \" variables in the dataset.\")\n\n"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Tokenize the text"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>words</th>\n      <th>#tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n      <td>[this, process,, however,, afforded, me, no, means, of, ascertaining, the, dimensions, of, my, dungeon;, as, i, might, make, its, circuit,, and, return, to, the, point, whence, i, set, out,, without, being, aware, of, the, fact;, so, perfectly, uniform, seemed, the, wall.]</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n      <td>[it, never, once, occurred, to, me, that, the, fumbling, might, be, a, mere, mistake.]</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n      <td>[in, his, left, hand, was, a, gold, snuff, box,, from, which,, as, he, capered, down, the, hill,, cutting, all, manner, of, fantastic, steps,, he, took, snuff, incessantly, with, an, air, of, the, greatest, possible, self, satisfaction.]</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n      <td>[how, lovely, is, spring, as, we, looked, from, windsor, terrace, on, the, sixteen, fertile, counties, spread, beneath,, speckled, by, happy, cottages, and, wealthier, towns,, all, looked, as, in, former, years,, heart, cheering, and, fair.]</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n      <td>[finding, nothing, else,, not, even, gold,, the, superintendent, abandoned, his, attempts;, but, a, perplexed, look, occasionally, steals, over, his, countenance, as, he, sits, thinking, at, his, desk.]</td>\n      <td>27</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                                                                                                                                                                                                                                      text  \\\n0  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n1  It never once occurred to me that the fumbling might be a mere mistake.                                                                                                                                                                   \n2  In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.                                  \n3  How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.                            \n4  Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.                                                            \n\n                                                                                                                                                                                                                                                                               words  \\\n0  [this, process,, however,, afforded, me, no, means, of, ascertaining, the, dimensions, of, my, dungeon;, as, i, might, make, its, circuit,, and, return, to, the, point, whence, i, set, out,, without, being, aware, of, the, fact;, so, perfectly, uniform, seemed, the, wall.]   \n1  [it, never, once, occurred, to, me, that, the, fumbling, might, be, a, mere, mistake.]                                                                                                                                                                                              \n2  [in, his, left, hand, was, a, gold, snuff, box,, from, which,, as, he, capered, down, the, hill,, cutting, all, manner, of, fantastic, steps,, he, took, snuff, incessantly, with, an, air, of, the, greatest, possible, self, satisfaction.]                                       \n3  [how, lovely, is, spring, as, we, looked, from, windsor, terrace, on, the, sixteen, fertile, counties, spread, beneath,, speckled, by, happy, cottages, and, wealthier, towns,, all, looked, as, in, former, years,, heart, cheering, and, fair.]                                   \n4  [finding, nothing, else,, not, even, gold,, the, superintendent, abandoned, his, attempts;, but, a, perplexed, look, occasionally, steals, over, his, countenance, as, he, sits, thinking, at, his, desk.]                                                                          \n\n   #tokens  \n0  41       \n1  14       \n2  36       \n3  34       \n4  27       "
                    }, 
                    "execution_count": 8
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 8, 
            "source": "from pyspark.ml.feature import Tokenizer, RegexTokenizer\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import IntegerType\n\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n\ncountTokens = udf(lambda words: len(words), IntegerType())\n\ntokenized = tokenizer.transform(data)\n(tokenized.select(\"text\", \"words\")\n    .withColumn(\"#tokens\", countTokens(col(\"words\"))).toPandas().head())"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Remove common words"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>words</th>\n      <th>filtered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n      <td>[this, process,, however,, afforded, me, no, means, of, ascertaining, the, dimensions, of, my, dungeon;, as, i, might, make, its, circuit,, and, return, to, the, point, whence, i, set, out,, without, being, aware, of, the, fact;, so, perfectly, uniform, seemed, the, wall.]</td>\n      <td>[process,, however,, afforded, means, ascertaining, dimensions, dungeon;, might, make, circuit,, return, point, whence, set, out,, without, aware, fact;, perfectly, uniform, seemed, wall.]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n      <td>[it, never, once, occurred, to, me, that, the, fumbling, might, be, a, mere, mistake.]</td>\n      <td>[never, occurred, fumbling, might, mere, mistake.]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n      <td>[in, his, left, hand, was, a, gold, snuff, box,, from, which,, as, he, capered, down, the, hill,, cutting, all, manner, of, fantastic, steps,, he, took, snuff, incessantly, with, an, air, of, the, greatest, possible, self, satisfaction.]</td>\n      <td>[left, hand, gold, snuff, box,, which,, capered, hill,, cutting, manner, fantastic, steps,, took, snuff, incessantly, air, greatest, possible, self, satisfaction.]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n      <td>[how, lovely, is, spring, as, we, looked, from, windsor, terrace, on, the, sixteen, fertile, counties, spread, beneath,, speckled, by, happy, cottages, and, wealthier, towns,, all, looked, as, in, former, years,, heart, cheering, and, fair.]</td>\n      <td>[lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath,, speckled, happy, cottages, wealthier, towns,, looked, former, years,, heart, cheering, fair.]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n      <td>[finding, nothing, else,, not, even, gold,, the, superintendent, abandoned, his, attempts;, but, a, perplexed, look, occasionally, steals, over, his, countenance, as, he, sits, thinking, at, his, desk.]</td>\n      <td>[finding, nothing, else,, even, gold,, superintendent, abandoned, attempts;, perplexed, look, occasionally, steals, countenance, sits, thinking, desk.]</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                                                                                                                                                                                                                                      text  \\\n0  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n1  It never once occurred to me that the fumbling might be a mere mistake.                                                                                                                                                                   \n2  In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.                                  \n3  How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.                            \n4  Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.                                                            \n\n                                                                                                                                                                                                                                                                               words  \\\n0  [this, process,, however,, afforded, me, no, means, of, ascertaining, the, dimensions, of, my, dungeon;, as, i, might, make, its, circuit,, and, return, to, the, point, whence, i, set, out,, without, being, aware, of, the, fact;, so, perfectly, uniform, seemed, the, wall.]   \n1  [it, never, once, occurred, to, me, that, the, fumbling, might, be, a, mere, mistake.]                                                                                                                                                                                              \n2  [in, his, left, hand, was, a, gold, snuff, box,, from, which,, as, he, capered, down, the, hill,, cutting, all, manner, of, fantastic, steps,, he, took, snuff, incessantly, with, an, air, of, the, greatest, possible, self, satisfaction.]                                       \n3  [how, lovely, is, spring, as, we, looked, from, windsor, terrace, on, the, sixteen, fertile, counties, spread, beneath,, speckled, by, happy, cottages, and, wealthier, towns,, all, looked, as, in, former, years,, heart, cheering, and, fair.]                                   \n4  [finding, nothing, else,, not, even, gold,, the, superintendent, abandoned, his, attempts;, but, a, perplexed, look, occasionally, steals, over, his, countenance, as, he, sits, thinking, at, his, desk.]                                                                          \n\n                                                                                                                                                                                       filtered  \n0  [process,, however,, afforded, means, ascertaining, dimensions, dungeon;, might, make, circuit,, return, point, whence, set, out,, without, aware, fact;, perfectly, uniform, seemed, wall.]  \n1  [never, occurred, fumbling, might, mere, mistake.]                                                                                                                                            \n2  [left, hand, gold, snuff, box,, which,, capered, hill,, cutting, manner, fantastic, steps,, took, snuff, incessantly, air, greatest, possible, self, satisfaction.]                           \n3  [lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath,, speckled, happy, cottages, wealthier, towns,, looked, former, years,, heart, cheering, fair.]        \n4  [finding, nothing, else,, even, gold,, superintendent, abandoned, attempts;, perplexed, look, occasionally, steals, countenance, sits, thinking, desk.]                                       "
                    }, 
                    "execution_count": 9
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 9, 
            "source": "from pyspark.ml.feature import StopWordsRemover\n\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setCaseSensitive(False)\nremoved = remover.transform(tokenized)\nremoved.select(\"text\", \"words\", \"filtered\" ).toPandas().head()"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### Show list of common words removed"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "i\nme\nmy\nmyself\nwe\nour\nours\nourselves\nyou\nyour\nyours\nyourself\nyourselves\nhe\nhim\nhis\nhimself\nshe\nher\nhers\nherself\nit\nits\nitself\nthey\nthem\ntheir\ntheirs\nthemselves\nwhat\nwhich\nwho\nwhom\nthis\nthat\nthese\nthose\nam\nis\nare\nwas\nwere\nbe\nbeen\nbeing\nhave\nhas\nhad\nhaving\ndo\ndoes\ndid\ndoing\na\nan\nthe\nand\nbut\nif\nor\nbecause\nas\nuntil\nwhile\nof\nat\nby\nfor\nwith\nabout\nagainst\nbetween\ninto\nthrough\nduring\nbefore\nafter\nabove\nbelow\nto\nfrom\nup\ndown\nin\nout\non\noff\nover\nunder\nagain\nfurther\nthen\nonce\nhere\nthere\nwhen\nwhere\nwhy\nhow\nall\nany\nboth\neach\nfew\nmore\nmost\nother\nsome\nsuch\nno\nnor\nnot\nonly\nown\nsame\nso\nthan\ntoo\nvery\ns\nt\ncan\nwill\njust\ndon\nshould\nnow\nd\nll\nm\no\nre\nve\ny\nain\naren\ncouldn\ndidn\ndoesn\nhadn\nhasn\nhaven\nisn\nma\nmightn\nmustn\nneedn\nshan\nshouldn\nwasn\nweren\nwon\nwouldn\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None]"
                    }, 
                    "execution_count": 10
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 10, 
            "source": "from __future__ import print_function\n[print(x) for x in remover.getStopWords()]"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Hash the words and inverse weight words that occur frequently across all text"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>rawFeatures</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0)</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.71404795764, 0.0, 0.0, 0.0, 1.72474875895, 3.95212637445, 0.0, 0.0, 0.0, 0.0, 0.0, 2.05017115938, 1.47962630091, 0.0, 0.0, 0.0, 0.0, 1.43706668649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.90707031574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.72474875895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8425317946, 1.8425317946, 0.0, 0.0, 2.21722524404, 1.97606318723, 1.8425317946, 1.43706668649, 2.31253542385, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 0.0, 4.10034231876, 0.0, 0.0, 0.0, 0.0, 2.05017115938)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.13021386705, 0.0, 1.35702397882, 0.0, 0.0, 0.0, 0.0, 0.0, 2.05017115938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.13021386705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.43706668649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.31253542385, 0.0, 0.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0)</td>\n      <td>(2.21722524404, 0.0, 0.0, 1.67068153767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 2.41789593951, 4.26042773411, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 2.05017115938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.33842073557, 0.0, 0.0, 0.0, 0.0, 0.0, 1.97606318723, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 0.0, 2.13021386705, 0.0, 1.90707031574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.97606318723, 2.05017115938, 0.0, 2.31253542385, 0.0, 1.67068153767, 0.0)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.72474875895, 0.0, 0.0, 1.57059807912, 1.72474875895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.65167573213, 0.0, 1.43706668649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 3.81414063148, 2.13021386705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.05017115938, 1.97606318723, 2.66921036779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.31928365084, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 0.0, 2.13021386705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 1.8425317946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 1.72474875895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8425317946, 0.0, 1.8425317946, 1.43706668649, 0.0, 0.0, 4.10034231876, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 5.07135795032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.72474875895, 0.0, 2.13021386705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8425317946, 0.0, 2.31253542385, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.31253542385, 0.0, 0.0, 0.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                                                                                                                                                                                                                                      text  \\\n0  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n1  It never once occurred to me that the fumbling might be a mere mistake.                                                                                                                                                                   \n2  In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.                                  \n3  How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.                            \n4  Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.                                                            \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            rawFeatures  \\\n0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0)   \n1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)   \n2  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0)   \n3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)   \n4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          features  \n0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.71404795764, 0.0, 0.0, 0.0, 1.72474875895, 3.95212637445, 0.0, 0.0, 0.0, 0.0, 0.0, 2.05017115938, 1.47962630091, 0.0, 0.0, 0.0, 0.0, 1.43706668649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.90707031574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.72474875895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8425317946, 1.8425317946, 0.0, 0.0, 2.21722524404, 1.97606318723, 1.8425317946, 1.43706668649, 2.31253542385, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 0.0, 4.10034231876, 0.0, 0.0, 0.0, 0.0, 2.05017115938)  \n1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.13021386705, 0.0, 1.35702397882, 0.0, 0.0, 0.0, 0.0, 0.0, 2.05017115938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.13021386705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.43706668649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.31253542385, 0.0, 0.0, 0.0)                                                                                                                                 \n2  (2.21722524404, 0.0, 0.0, 1.67068153767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 2.41789593951, 4.26042773411, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 2.05017115938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.33842073557, 0.0, 0.0, 0.0, 0.0, 0.0, 1.97606318723, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 0.0, 2.13021386705, 0.0, 1.90707031574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.97606318723, 2.05017115938, 0.0, 2.31253542385, 0.0, 1.67068153767, 0.0)         \n3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.72474875895, 0.0, 0.0, 1.57059807912, 1.72474875895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.65167573213, 0.0, 1.43706668649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 3.81414063148, 2.13021386705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.05017115938, 1.97606318723, 2.66921036779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.31928365084, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 0.0, 2.13021386705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 1.8425317946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)          \n4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.57059807912, 0.0, 1.72474875895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8425317946, 0.0, 1.8425317946, 1.43706668649, 0.0, 0.0, 4.10034231876, 0.0, 0.0, 0.0, 0.0, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 5.07135795032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.72474875895, 0.0, 2.13021386705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8425317946, 0.0, 2.31253542385, 0.0, 2.21722524404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.31253542385, 0.0, 0.0, 0.0)                                                    "
                    }, 
                    "execution_count": 11
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 11, 
            "source": "from pyspark.ml.feature import HashingTF, IDF\n\nhashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=100)\nfeaturizedData = hashingTF.transform(removed)\n\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\nidfModel = idf.fit(featurizedData)\nrescaledData = idfModel.transform(featurizedData)\n\nrescaledData.select(\"text\", \"rawFeatures\", \"features\").toPandas().head()"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Encode the label column"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 12, 
            "source": "from pyspark.ml.feature import StringIndexer\nlabelIndexer = StringIndexer(inputCol='author', outputCol='label').fit(data)"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Use Logistic Regression Algorithm to predict author"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 13, 
            "source": "from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(labelCol = \"label\", maxIter=10, regParam=0.3, threshold=0.7)\n#lr = LogisticRegression(labelCol = 'label', maxIter=10, regParam=0.3, elasticNetParam=0.8)"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Convert indexed labels back to original labels"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 14, 
            "source": "from pyspark.ml.feature import IndexToString\nlabelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Define the machine learning pipeline"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 15, 
            "source": "stages = [tokenizer, remover, hashingTF, idf, labelIndexer, lr, labelConverter]\nfrom pyspark.ml import Pipeline\npipeline = Pipeline(stages = stages)"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### Display the parameter setting of the pipeline stages"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Tokenizer:\ninputCol: input column name. (current: text)\noutputCol: output column name. (default: Tokenizer_4227971a5803d5f8a5ce__output, current: words)\n*************************\nRemover:\ncaseSensitive: whether to do a case sensitive comparison over the stop words (default: False, current: False)\ninputCol: input column name. (current: words)\noutputCol: output column name. (default: StopWordsRemover_4fce913f94309d138f97__output, current: filtered)\nstopWords: The words to be filtered out (default: [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn'])\n*************************\nHashingTF:\nbinary: If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts. Default False. (default: False)\ninputCol: input column name. (current: filtered)\nnumFeatures: number of features. (default: 262144, current: 100)\noutputCol: output column name. (default: HashingTF_44d5abe5d044d87debfc__output, current: rawFeatures)\n*************************\nIDF:\ninputCol: input column name. (current: rawFeatures)\nminDocFreq: minimum number of documents in which a term should appear for filtering (default: 0)\noutputCol: output column name. (default: IDF_42f894653fcd82d2c21b__output, current: features)\n*************************\nLogisticRegression:\naggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\nelasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\nfamily: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\nfeaturesCol: features column name. (default: features)\nfitIntercept: whether to fit an intercept term. (default: True)\nlabelCol: label column name. (default: label, current: label)\nmaxIter: max number of iterations (>= 0). (default: 100, current: 10)\npredictionCol: prediction column name. (default: prediction)\nprobabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\nrawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\nregParam: regularization parameter (>= 0). (default: 0.0, current: 0.3)\nstandardization: whether to standardize the training features before fitting the model. (default: True)\nthreshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5, current: 0.7)\nthresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\ntol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n*************************\nPipeline:\nstages: a list of pipeline stages (current: [Tokenizer_4227971a5803d5f8a5ce, StopWordsRemover_4fce913f94309d138f97, HashingTF_44d5abe5d044d87debfc, IDF_42f894653fcd82d2c21b, StringIndexer_4c18b0bab5a47f92ef85, LogisticRegression_4befb895d2b6a42d35a8, IndexToString_4a6d9d0a729955c23361])\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 16, 
            "source": "print(\"Tokenizer:\")\nprint(tokenizer.explainParams())\nprint(\"*************************\")\nprint(\"Remover:\")\nprint(remover.explainParams())\nprint(\"*************************\")\nprint(\"HashingTF:\")\nprint(hashingTF.explainParams())\nprint(\"*************************\")\nprint(\"IDF:\")\nprint(idf.explainParams())\nprint(\"*************************\")\nprint(\"LogisticRegression:\")\nprint(lr.explainParams())\nprint(\"*************************\")\nprint(\"Pipeline:\")\nprint(pipeline.explainParams())"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Split the dataset into training and test data sets"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "The number of records in the traininig data set is 77.\nThe number of rows labeled EAP in the training data set is 27.\nThe number of rows labeled HPL in the training data set is 25.\nThe number of rows labeled MWS in the training data set is 25.\nThe number of records in the test data set is 23.\nThe number of rows labeled EAP in the test data set is 9.\nThe number of rows labeled HPL in the test data set is 8.\nThe number of rows labeled MWS in the test data set is 6.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 17, 
            "source": "train, test = data.randomSplit([70.0,30.0], seed=1)\nprint('The number of records in the traininig data set is {}.'.format(train.count()))\nprint('The number of rows labeled EAP in the training data set is {}.'.format(train.filter(train['author'] == 'EAP').count()))\nprint('The number of rows labeled HPL in the training data set is {}.'.format(train.filter(train['author'] == 'HPL').count()))\nprint('The number of rows labeled MWS in the training data set is {}.'.format(train.filter(train['author'] == 'MWS').count()))\n\nprint('The number of records in the test data set is {}.'.format(test.count()))\nprint('The number of rows labeled EAP in the test data set is {}.'.format(test.filter(test['author'] == 'EAP').count()))\nprint('The number of rows labeled HPL in the test data set is {}.'.format(test.filter(test['author'] == 'HPL').count()))\nprint('The number of rows labeled MWS in the test data set is {}.'.format(test.filter(test['author'] == 'MWS').count()))"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Train the model using the training data set"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 18, 
            "source": "model = pipeline.fit(train)"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Make predictions using the test data set"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 19, 
            "source": "predictions = model.transform(test)"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>label</th>\n      <th>prediction</th>\n      <th>predictedLabel</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MWS</td>\n      <td>2</td>\n      <td>2</td>\n      <td>MWS</td>\n      <td>[0.333603184945, 0.259378643869, 0.407018171186]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MWS</td>\n      <td>2</td>\n      <td>1</td>\n      <td>HPL</td>\n      <td>[0.14545299873, 0.506132146855, 0.348414854416]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HPL</td>\n      <td>1</td>\n      <td>1</td>\n      <td>HPL</td>\n      <td>[0.343832262321, 0.386505251073, 0.269662486606]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MWS</td>\n      <td>2</td>\n      <td>2</td>\n      <td>MWS</td>\n      <td>[0.124928674119, 0.0717508395858, 0.803320486295]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HPL</td>\n      <td>1</td>\n      <td>1</td>\n      <td>HPL</td>\n      <td>[0.282942583593, 0.540385561467, 0.17667185494]</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  author  label  prediction predictedLabel  \\\n0  MWS    2      2           MWS             \n1  MWS    2      1           HPL             \n2  HPL    1      1           HPL             \n3  MWS    2      2           MWS             \n4  HPL    1      1           HPL             \n\n                                         probability  \n0  [0.333603184945, 0.259378643869, 0.407018171186]   \n1  [0.14545299873, 0.506132146855, 0.348414854416]    \n2  [0.343832262321, 0.386505251073, 0.269662486606]   \n3  [0.124928674119, 0.0717508395858, 0.803320486295]  \n4  [0.282942583593, 0.540385561467, 0.17667185494]    "
                    }, 
                    "execution_count": 20
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 20, 
            "source": "predictions.select(\"author\", \"label\", \"prediction\", 'predictedLabel', \"probability\").toPandas().head()"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Evaluate the model performance by calculating the accuracy"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Accuracy = 0.478260869565.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 22, 
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol=\"prediction\").setMetricName(\"accuracy\")\nprint('Accuracy = {}.'.format(evaluator.evaluate(predictions)))"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Investigate the prediction results results"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Predicted EAP correctly 5 times.\nFailed to predict EAP 4 times.\nPredicted EAP incorrectly 5 times.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 64, 
            "source": "EAPandEAP = predictions.filter(predictions['author']=='EAP').filter(predictions['predictedLabel']=='EAP').count()\nEAPnotEAP = predictions.filter(predictions['author']=='EAP').filter(predictions['predictedLabel']!='EAP').count()\nnotEAPbutEAP = predictions.filter(predictions['author']!='EAP').filter(predictions['predictedLabel']=='EAP').count()\nprint(\"Predicted EAP correctly {} times.\".format(EAPandEAP))\nprint(\"Failed to predict EAP {} times.\".format(EAPnotEAP))\nprint(\"Predicted EAP incorrectly {} times.\".format(notEAPbutEAP))"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Predicted HPL correctly 4 times.\nFailed to predict HPL 4 times.\nPredicted HPL incorrectly 4 times.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 65, 
            "source": "HPLandHPL = predictions.filter(predictions['author']=='HPL').filter(predictions['predictedLabel']=='HPL').count()\nHPLnotHPL = predictions.filter(predictions['author']=='HPL').filter(predictions['predictedLabel']!='HPL').count()\nnotHPLbutHPL = predictions.filter(predictions['author']!='HPL').filter(predictions['predictedLabel']=='HPL').count()\nprint(\"Predicted HPL correctly {} times.\".format(HPLandHPL))\nprint(\"Failed to predict HPL {} times.\".format(HPLnotHPL))\nprint(\"Predicted HPL incorrectly {} times.\".format(notHPLbutHPL))"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Predicted MWS correctly 2 times.\nFailed to predict MWS 4 times.\nPredicted MWS incorrectly 3 times.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 66, 
            "source": "MWSandMWS = predictions.filter(predictions['author']=='MWS').filter(predictions['predictedLabel']=='MWS').count()\nMWSnotMWS = predictions.filter(predictions['author']=='MWS').filter(predictions['predictedLabel']!='MWS').count()\nnotMWSbutMWS = predictions.filter(predictions['author']!='MWS').filter(predictions['predictedLabel']=='MWS').count()\nprint(\"Predicted MWS correctly {} times.\".format(MWSandMWS))\nprint(\"Failed to predict MWS {} times.\".format(MWSnotMWS))\nprint(\"Predicted MWS incorrectly {} times.\".format(notMWSbutMWS))"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# Use Natural Language Understanding to create rich features"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Setup configuration for the Natural La service"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 23, 
            "source": "import watson_developer_cloud\nfrom watson_developer_cloud import NaturalLanguageUnderstandingV1\nimport watson_developer_cloud.natural_language_understanding.features.v1 as Features\nimport json"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 24, 
            "source": "NLU_USERNAME = 'c15be849-aa59-4a88-b30a-6d0a22e308be'\nNLU_PASSWORD = 'm7cKrXz7aW5h'\nnatural_language_understanding = NaturalLanguageUnderstandingV1(\n  username=NLU_USERNAME,\n  password=NLU_PASSWORD,\n  version=\"2017-02-27\")"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### Randomly pick text from dataset to analyze"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\"This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.\"\n\nAnger = 0.22525\nJoy = 0.208037\nSadness = 0.156157\nFear = 0.092108\nDisgust = 0.024618\nSentiment = 0.834411\n\n{\n  \"usage\": {\n    \"text_characters\": 233, \n    \"features\": 2, \n    \"text_units\": 1\n  }, \n  \"emotion\": {\n    \"document\": {\n      \"emotion\": {\n        \"anger\": 0.22525, \n        \"joy\": 0.208037, \n        \"sadness\": 0.156157, \n        \"fear\": 0.092108, \n        \"disgust\": 0.024618\n      }\n    }\n  }, \n  \"language\": \"en\", \n  \"sentiment\": {\n    \"document\": {\n      \"score\": 0.834411, \n      \"label\": \"positive\"\n    }\n  }\n}\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 26, 
            "source": "dataNLU = data.select(data[\"text\"]).toJSON().collect()[0][8:-1]\nprint(dataNLU)\nimport json\nfeatures=[\n    Features.Emotion(),\n    Features.Sentiment()\n  ]\nnlu = natural_language_understanding.analyze(text=dataNLU, features=features)\nanger = nlu['emotion']['document']['emotion']['anger']\njoy = nlu['emotion']['document']['emotion']['joy']\nsadness = nlu['emotion']['document']['emotion']['sadness']\nfear = nlu['emotion']['document']['emotion']['fear']\ndisgust = nlu['emotion']['document']['emotion']['disgust']\nsentiment = nlu['sentiment']['document']['score']\n\nprint(\"\")\nprint(\"Anger = {}\".format(anger))\nprint(\"Joy = {}\".format(joy))\nprint(\"Sadness = {}\".format(sadness))\nprint(\"Fear = {}\".format(fear))\nprint(\"Disgust = {}\".format(disgust))\nprint(\"Sentiment = {}\".format(sentiment))\nprint(\"\")\nprint(json.dumps(nlu, indent=2))"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Define UDFs to create NLU derived features"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 30, 
            "source": "from pyspark.sql.types import FloatType\nfrom pyspark.sql.functions import udf\nudfAnger = (udf(lambda text: NaturalLanguageUnderstandingV1(\n    username=NLU_USERNAME, password=NLU_PASSWORD, version=\"2017-02-27\")\n    .analyze(text=text, features=features)['emotion']['document']['emotion']['anger'],\n    FloatType()))\nudfJoy = (udf(lambda text: NaturalLanguageUnderstandingV1(\n    username=NLU_USERNAME, password=NLU_PASSWORD, version=\"2017-02-27\")\n    .analyze(text=text, features=features)['emotion']['document']['emotion']['joy'],\n    FloatType()))\nudfSadness = (udf(lambda text: NaturalLanguageUnderstandingV1(\n    username=NLU_USERNAME, password=NLU_PASSWORD, version=\"2017-02-27\")\n    .analyze(text=text, features=features)['emotion']['document']['emotion']['sadness'],\n    FloatType()))\nudfFear = (udf(lambda text: NaturalLanguageUnderstandingV1(\n    username=NLU_USERNAME, password=NLU_PASSWORD, version=\"2017-02-27\")\n    .analyze(text=text, features=features)['emotion']['document']['emotion']['fear'],\n    FloatType()))\nudfDisgust = (udf(lambda text: NaturalLanguageUnderstandingV1(\n    username=NLU_USERNAME, password=NLU_PASSWORD, version=\"2017-02-27\")\n    .analyze(text=text, features=features)['emotion']['document']['emotion']['disgust'],\n    FloatType()))\nudfSentiment = (udf(lambda text: NaturalLanguageUnderstandingV1(\n    username=NLU_USERNAME, password=NLU_PASSWORD, version=\"2017-02-27\")\n    .analyze(text=text, features=features)['sentiment']['document']['score'],\n    FloatType()))"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "### Use limited data set for processing efficiency"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id26305</td>\n      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n      <td>EAP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id17569</td>\n      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n      <td>HPL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id11008</td>\n      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n      <td>EAP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27763</td>\n      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n      <td>MWS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id12958</td>\n      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n      <td>HPL</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "        id  \\\n0  id26305   \n1  id17569   \n2  id11008   \n3  id27763   \n4  id12958   \n\n                                                                                                                                                                                                                                      text  \\\n0  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n1  It never once occurred to me that the fumbling might be a mere mistake.                                                                                                                                                                   \n2  In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.                                  \n3  How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.                            \n4  Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.                                                            \n\n  author  \n0  EAP    \n1  HPL    \n2  EAP    \n3  MWS    \n4  HPL    "
                    }, 
                    "execution_count": 31
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 31, 
            "source": "data2 = data.limit(100)\ndata2.toPandas().head()"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Anger</th>\n      <th>Joy</th>\n      <th>Sadness</th>\n      <th>Fear</th>\n      <th>Disgust</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.225250</td>\n      <td>0.208037</td>\n      <td>0.156157</td>\n      <td>0.092108</td>\n      <td>0.024618</td>\n      <td>0.875231</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.268703</td>\n      <td>0.073350</td>\n      <td>0.284674</td>\n      <td>0.336473</td>\n      <td>0.049945</td>\n      <td>-0.867677</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.047614</td>\n      <td>0.856397</td>\n      <td>0.021778</td>\n      <td>0.017659</td>\n      <td>0.061879</td>\n      <td>-0.739374</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.002317</td>\n      <td>0.895471</td>\n      <td>0.074464</td>\n      <td>0.011802</td>\n      <td>0.011855</td>\n      <td>0.928205</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.239133</td>\n      <td>0.005415</td>\n      <td>0.435080</td>\n      <td>0.343188</td>\n      <td>0.311778</td>\n      <td>-0.717046</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.030202</td>\n      <td>0.380229</td>\n      <td>0.316263</td>\n      <td>0.011006</td>\n      <td>0.016229</td>\n      <td>0.987105</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.146274</td>\n      <td>0.034530</td>\n      <td>0.189046</td>\n      <td>0.644884</td>\n      <td>0.066424</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.175506</td>\n      <td>0.159886</td>\n      <td>0.116204</td>\n      <td>0.363028</td>\n      <td>0.305100</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.007289</td>\n      <td>0.177620</td>\n      <td>0.575457</td>\n      <td>0.321208</td>\n      <td>0.025653</td>\n      <td>0.569564</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.073041</td>\n      <td>0.262087</td>\n      <td>0.175994</td>\n      <td>0.142699</td>\n      <td>0.117686</td>\n      <td>-0.851087</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "      Anger       Joy   Sadness      Fear   Disgust  Sentiment\n0  0.225250  0.208037  0.156157  0.092108  0.024618  0.875231 \n1  0.268703  0.073350  0.284674  0.336473  0.049945 -0.867677 \n2  0.047614  0.856397  0.021778  0.017659  0.061879 -0.739374 \n3  0.002317  0.895471  0.074464  0.011802  0.011855  0.928205 \n4  0.239133  0.005415  0.435080  0.343188  0.311778 -0.717046 \n5  0.030202  0.380229  0.316263  0.011006  0.016229  0.987105 \n6  0.146274  0.034530  0.189046  0.644884  0.066424  0.000000 \n7  0.175506  0.159886  0.116204  0.363028  0.305100  0.000000 \n8  0.007289  0.177620  0.575457  0.321208  0.025653  0.569564 \n9  0.073041  0.262087  0.175994  0.142699  0.117686 -0.851087 "
                    }, 
                    "execution_count": 32
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 32, 
            "source": "data2 = (data2.withColumn('Anger', udfAnger(data2['text']))\n        .withColumn('Joy', udfJoy(data2['text']))\n        .withColumn('Sadness', udfSadness(data2['text']))\n        .withColumn('Fear', udfFear(data2['text']))\n        .withColumn('Disgust', udfDisgust(data2['text']))\n        .withColumn('Sentiment', udfSentiment(data2['text'])))\ndata2.cache()\ndata2.select(data2['Anger'], data2['Joy'], data2['Sadness'], data2['Fear'], data2['Disgust'], data2['Sentiment']).toPandas().head(10)"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author</th>\n      <th>Anger</th>\n      <th>Joy</th>\n      <th>Sadness</th>\n      <th>Fear</th>\n      <th>Disgust</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id26305</td>\n      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n      <td>EAP</td>\n      <td>0.225250</td>\n      <td>0.208037</td>\n      <td>0.156157</td>\n      <td>0.092108</td>\n      <td>0.024618</td>\n      <td>0.875231</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id17569</td>\n      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n      <td>HPL</td>\n      <td>0.268703</td>\n      <td>0.073350</td>\n      <td>0.284674</td>\n      <td>0.336473</td>\n      <td>0.049945</td>\n      <td>-0.867677</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id11008</td>\n      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n      <td>EAP</td>\n      <td>0.047614</td>\n      <td>0.856397</td>\n      <td>0.021778</td>\n      <td>0.017659</td>\n      <td>0.061879</td>\n      <td>-0.739374</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27763</td>\n      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n      <td>MWS</td>\n      <td>0.002317</td>\n      <td>0.895471</td>\n      <td>0.074464</td>\n      <td>0.011802</td>\n      <td>0.011855</td>\n      <td>0.928205</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id12958</td>\n      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n      <td>HPL</td>\n      <td>0.239133</td>\n      <td>0.005415</td>\n      <td>0.435080</td>\n      <td>0.343188</td>\n      <td>0.311778</td>\n      <td>-0.717046</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "        id  \\\n0  id26305   \n1  id17569   \n2  id11008   \n3  id27763   \n4  id12958   \n\n                                                                                                                                                                                                                                      text  \\\n0  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n1  It never once occurred to me that the fumbling might be a mere mistake.                                                                                                                                                                   \n2  In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.                                  \n3  How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.                            \n4  Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.                                                            \n\n  author     Anger       Joy   Sadness      Fear   Disgust  Sentiment  \n0  EAP    0.225250  0.208037  0.156157  0.092108  0.024618  0.875231   \n1  HPL    0.268703  0.073350  0.284674  0.336473  0.049945 -0.867677   \n2  EAP    0.047614  0.856397  0.021778  0.017659  0.061879 -0.739374   \n3  MWS    0.002317  0.895471  0.074464  0.011802  0.011855  0.928205   \n4  HPL    0.239133  0.005415  0.435080  0.343188  0.311778 -0.717046   "
                    }, 
                    "execution_count": 33
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 33, 
            "source": "data2.toPandas().head()"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Rerun Model with NLU Features Added"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 34, 
            "source": "train2, test2 = data2.randomSplit([70.0,30.0], seed=1)"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 35, 
            "source": "from pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(inputCols=[\"features\", \"Anger\", \"Joy\", \"Sadness\", \"Fear\", \"Disgust\",\"Sentiment\"], outputCol=\"features2\")"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 36, 
            "source": "lr = LogisticRegression(labelCol = \"label\", featuresCol= \"features2\", maxIter=10, regParam=0.3, threshold=0.7)\nstages2 = [tokenizer, remover, hashingTF, idf, assembler, labelIndexer, lr, labelConverter]\npipeline2 = Pipeline(stages = stages2)"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 37, 
            "source": "model2 = pipeline2.fit(train2)"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 38, 
            "source": "predictions2 = model2.transform(test2)"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>label</th>\n      <th>prediction</th>\n      <th>predictedLabel</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MWS</td>\n      <td>2</td>\n      <td>2</td>\n      <td>MWS</td>\n      <td>[0.309468385722, 0.221262936173, 0.469268678105]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MWS</td>\n      <td>2</td>\n      <td>1</td>\n      <td>HPL</td>\n      <td>[0.19436539635, 0.563329407895, 0.242305195755]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HPL</td>\n      <td>1</td>\n      <td>1</td>\n      <td>HPL</td>\n      <td>[0.33304496925, 0.375787198297, 0.291167832453]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MWS</td>\n      <td>2</td>\n      <td>2</td>\n      <td>MWS</td>\n      <td>[0.137431710759, 0.0768537530022, 0.785714536239]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HPL</td>\n      <td>1</td>\n      <td>1</td>\n      <td>HPL</td>\n      <td>[0.268699509092, 0.658899041912, 0.0724014489959]</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  author  label  prediction predictedLabel  \\\n0  MWS    2      2           MWS             \n1  MWS    2      1           HPL             \n2  HPL    1      1           HPL             \n3  MWS    2      2           MWS             \n4  HPL    1      1           HPL             \n\n                                         probability  \n0  [0.309468385722, 0.221262936173, 0.469268678105]   \n1  [0.19436539635, 0.563329407895, 0.242305195755]    \n2  [0.33304496925, 0.375787198297, 0.291167832453]    \n3  [0.137431710759, 0.0768537530022, 0.785714536239]  \n4  [0.268699509092, 0.658899041912, 0.0724014489959]  "
                    }, 
                    "execution_count": 39
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 39, 
            "source": "predictions2.select(\"author\", \"label\", \"prediction\", 'predictedLabel', \"probability\").toPandas().head()"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Accuracy = 0.521739130435.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 51, 
            "source": "evaluator2 = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol=\"prediction\").setMetricName(\"accuracy\")\nprint('Accuracy = {}.'.format(evaluator.evaluate(predictions2)))"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Investigate Improved Results"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Predicted EAP correctly 6 times vs. 5 previously.\nFailed to predict EAP 3 times vs. 4 previously.\nPredicted EAP incorrectly 5 times vs. 5 previously.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 75, 
            "source": "EAPandEAP2 = predictions2.filter(predictions2['author']=='EAP').filter(predictions2['predictedLabel']=='EAP').count()\nEAPnotEAP2 = predictions2.filter(predictions2['author']=='EAP').filter(predictions2['predictedLabel']!='EAP').count()\nnotEAPbutEAP2 = predictions2.filter(predictions2['author']!='EAP').filter(predictions2['predictedLabel']=='EAP').count()\nprint(\"Predicted EAP correctly {} times vs. {} previously.\".format(EAPandEAP2, EAPandEAP))\nprint(\"Failed to predict EAP {} times vs. {} previously.\".format(EAPnotEAP2, EAPnotEAP))\nprint(\"Predicted EAP incorrectly {} times vs. {} previously.\".format(notEAPbutEAP2, notEAPbutEAP))"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Predicted HPL correctly 4 times vs. 4 previously.\nFailed to predict HPL 4 times vs. 4 previously.\nPredicted HPL incorrectly 3 times vs. 4 previously.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 78, 
            "source": "HPLandHPL2 = predictions2.filter(predictions2['author']=='HPL').filter(predictions2['predictedLabel']=='HPL').count()\nHPLnotHPL2 = predictions2.filter(predictions2['author']=='HPL').filter(predictions2['predictedLabel']!='HPL').count()\nnotHPLbutHPL2 = predictions2.filter(predictions2['author']!='HPL').filter(predictions2['predictedLabel']=='HPL').count()\nprint(\"Predicted HPL correctly {} times vs. {} previously.\".format(HPLandHPL2, HPLandHPL))\nprint(\"Failed to predict HPL {} times vs. {} previously.\".format(HPLnotHPL2, HPLnotHPL))\nprint(\"Predicted HPL incorrectly {} times vs. {} previously.\".format(notHPLbutHPL2, notHPLbutHPL))"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Predicted MWS correctly 2 times vs. 2 previously.\nFailed to predict MWS 4 times vs. 4 previously.\nPredicted MWS incorrectly 3 times vs. 3 previously.\n"
                }
            ], 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 81, 
            "source": "MWSandMWS2 = predictions2.filter(predictions2['author']=='MWS').filter(predictions2['predictedLabel']=='MWS').count()\nMWSnotMWS2 = predictions2.filter(predictions2['author']=='MWS').filter(predictions2['predictedLabel']!='MWS').count()\nnotMWSbutMWS2 = predictions2.filter(predictions2['author']!='MWS').filter(predictions2['predictedLabel']=='MWS').count()\nprint(\"Predicted MWS correctly {} times vs. {} previously.\".format(MWSandMWS2, MWSandMWS))\nprint(\"Failed to predict MWS {} times vs. {} previously.\".format(MWSnotMWS2, MWSnotMWS))\nprint(\"Predicted MWS incorrectly {} times vs. {} previously.\".format(notMWSbutMWS2, notMWSbutMWS))"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "name": "python", 
            "file_extension": ".py", 
            "version": "2.7.11", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "pygments_lexer": "ipython2"
        }
    }, 
    "nbformat": 4
}